---
templateKey: blog-post
slug: pyspark
category1: it
category2: Hadoop
category3: pyspark
title: Pysparkについてまとめてみた
date: 2020-04-16T12:52:57.697Z
tags:
  - Pyspark
  - 分散処理
  - Hadoop
---
今の現場のデータ処理でPysparkを使用しているので、勉強がてらまとめてみました。

<br>

大規模なデータ処理を扱うミドルウェアとしてHadoopがありファイル管理、分散処理と大きく役割が分かれますが、Pysparkは分散処理を担うフレームワークになります。scalaで動いておりMap Reduceより高速化されています。

<br>

・何が優位なのか

RDD(Resilient Distributed Dataset)と言う分散処理を行えるDatasetを使用し、頻繁にアクセスを行うデータをファイルシステム上(HDFSの)キャッシュに保有できたりして高速化を実現しているらしいてす。



<br>

色々と説明は書かれているけど、まとめた情報としてはくれくらいで十分な気がしました。あとは使ってみたいと思います。

<br>

AWSのEMRはHadoopとPysparkをマネージドな環境で比較的簡単に使えるみたいで、興味があるので別の機会でまとめられたらと思います。